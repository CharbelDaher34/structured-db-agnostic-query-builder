#!/usr/bin/env python3
"""
Streamlit interface for visualizing Elasticsearch query results.
Reads from JSON file generated by elasticsearch_model_generator.py
"""

import json
import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime


def LoadData(filename: str = "example_queries.json") -> list:
    """Load query data from JSON or Excel file."""
    file_path = Path(filename)
    if not file_path.exists():
        return []
    
    try:
        if filename.endswith('.json'):
            data = json.loads(file_path.read_text())
            # Ensure data is a list
            if isinstance(data, dict):
                return [data]
            return data if isinstance(data, list) else []
        elif filename.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file_path)
            # Handle NaN values and convert to proper format
            df = df.fillna('')
            # Replace any remaining NaN values with empty strings
            df = df.replace([np.nan, 'nan', 'NaN'], '')
            records = df.to_dict('records')
            
            # Ensure each record has required fields and handle different column names
            for record in records:
                # Handle different input field names
                if 'input' not in record:
                    record['input'] = record.get('Query', record.get('Natural_Language_Query', record.get('query', 'Unknown query')))
                
                # Handle filter field - parse JSON string if needed
                if 'filter' not in record:
                    filter_data = record.get('Extracted_Filters', record.get('filter'))
                    if isinstance(filter_data, str):
                        try:
                            record['filter'] = json.loads(filter_data)
                        except (json.JSONDecodeError, TypeError):
                            record['filter'] = None
                    else:
                        record['filter'] = filter_data
                
                # Handle elastic_query field - parse JSON string if needed
                if 'elastic_query' not in record:
                    elastic_data = record.get('Elasticsearch_Queries', record.get('elastic_query'))
                    if isinstance(elastic_data, str):
                        try:
                            record['elastic_query'] = json.loads(elastic_data)
                        except (json.JSONDecodeError, TypeError):
                            record['elastic_query'] = None
                    else:
                        record['elastic_query'] = elastic_data
                
                # Handle status field
                if 'status' not in record:
                    record['status'] = record.get('API_Status', record.get('status', 'unknown'))
                
                # Handle timestamp if missing
                if 'timestamp' not in record:
                    record['timestamp'] = record.get('Processing_Time', '')
            
            return records
        else:
            # Try JSON first, then Excel
            try:
                data = json.loads(file_path.read_text())
                if isinstance(data, dict):
                    return [data]
                return data if isinstance(data, list) else []
            except json.JSONDecodeError:
                df = pd.read_excel(file_path)
                df = df.fillna('')
                # Replace any remaining NaN values with empty strings
                df = df.replace([np.nan, 'nan', 'NaN'], '')
                records = df.to_dict('records')
                
                # Ensure each record has required fields and handle different column names
                for record in records:
                    # Handle different input field names
                    if 'input' not in record:
                        record['input'] = record.get('Query', record.get('Natural_Language_Query', record.get('query', 'Unknown query')))
                    
                    # Handle filter field - parse JSON string if needed
                    if 'filter' not in record:
                        filter_data = record.get('Extracted_Filters', record.get('filter'))
                        if isinstance(filter_data, str):
                            try:
                                record['filter'] = json.loads(filter_data)
                            except (json.JSONDecodeError, TypeError):
                                record['filter'] = None
                        else:
                            record['filter'] = filter_data
                    
                    # Handle elastic_query field - parse JSON string if needed
                    if 'elastic_query' not in record:
                        elastic_data = record.get('Elasticsearch_Queries', record.get('elastic_query'))
                        if isinstance(elastic_data, str):
                            try:
                                record['elastic_query'] = json.loads(elastic_data)
                            except (json.JSONDecodeError, TypeError):
                                record['elastic_query'] = None
                        else:
                            record['elastic_query'] = elastic_data
                    
                    # Handle status field
                    if 'status' not in record:
                        record['status'] = record.get('API_Status', record.get('status', 'unknown'))
                    
                    # Handle timestamp if missing
                    if 'timestamp' not in record:
                        record['timestamp'] = record.get('Processing_Time', '')
                
                return records
    except (json.JSONDecodeError, FileNotFoundError, Exception):
        return []


def SaveData(data: list, filename: str) -> bool:
    """Save data to JSON or Excel file based on extension."""
    try:
        file_path = Path(filename)
        
        if filename.endswith('.json'):
            file_path.write_text(json.dumps(data, indent=2))
        elif filename.endswith(('.xlsx', '.xls')):
            df = pd.DataFrame(data)
            df.to_excel(file_path, index=False)
        else:
            # Default to JSON
            file_path.write_text(json.dumps(data, indent=2))
        
        return True
    except Exception:
        return False


def ValidateDataStructure(data: list) -> dict:
    """Validate the structure of loaded data and return diagnostics."""
    if not data:
        return {"valid": False, "error": "No data provided"}
    
    if not isinstance(data, list):
        return {"valid": False, "error": "Data must be a list of objects"}
    
    issues = []
    fixed_count = 0
    
    for i, item in enumerate(data):
        if not isinstance(item, dict):
            issues.append(f"Item {i+1} is not a dictionary")
            continue
            
        # Check for required fields
        if 'input' not in item:
            if any(key in item for key in ['Query', 'Natural_Language_Query', 'query']):
                fixed_count += 1
            else:
                issues.append(f"Item {i+1} missing 'input', 'Query', 'Natural_Language_Query', or 'query' field")
    
    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "total_items": len(data),
        "fixed_items": fixed_count,
        "sample_keys": list(data[0].keys()) if data else []
    }


def ProcessLiveQuery(query: str) -> dict:
    """Process a live query using the ElasticsearchModelGenerator."""
    try:
        # Import here to avoid circular imports
        from elasticsearch_model_generator import ElasticsearchModelGenerator
        
        client = ElasticsearchModelGenerator(
            index_name="user_transactions",
            category_fields=[
                "card_kind",
                "card_type", 
                "transaction.receiver.category_type",
                "transaction.receiver.location",
                "transaction.type",
                "transaction.currency",
                "transaction.receiver.name"
            ],
            fields_to_ignore=["user_id", "card_number"],
        )
        
        result = client.QueryFromNaturalLanguage(query, execute=False)
        return {
            "input": query,
            "filter": result["extracted_filters"],
            "elastic_query": result["elasticsearch_queries"],
            "status": "success"
        }
    except Exception as e:
        return {
            "input": query,
            "filter": None,
            "elastic_query": None,
            "status": "error",
            "error": str(e)
        }


def ProcessRawESQuery(query: dict) -> dict:
    """Process a raw ES query using the ElasticsearchModelGenerator."""
    try:
        from elasticsearch_model_generator import ElasticsearchModelGenerator
        
        client = ElasticsearchModelGenerator(
            index_name="user_transactions",
        )
        
        result = client.run_raw_elastic_query(query)
        return result
    except Exception as e:
        return {
            "error": str(e),
            "query": query
        }


def DisplayQueryCard(query_data: dict, index: int):
    """Display a single query result in an expandable card."""
    # Get input query with fallback
    input_query = query_data.get("input", "Unknown query")
    
    # Determine status based on presence of required fields
    has_filter = query_data.get("filter") is not None
    has_elastic_query = query_data.get("elastic_query") is not None
    status = "success" if has_filter and has_elastic_query else "error"
    
    # Create status indicator
    status_icon = "‚úÖ" if status == "success" else "‚ùå"
    status_color = "green" if status == "success" else "red"
    
    # Truncate query for display
    display_query = input_query[:60] + "..." if len(input_query) > 60 else input_query
    
    with st.expander(f"{status_icon} Query {index + 1}: {display_query}"):
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"**Query:** {input_query}")
        with col2:
            st.markdown(f"**Status:** :{status_color}[{status.upper()}]")
        
        if status == "success":
            # Show filters
            st.subheader("üîç Extracted Filters")
            if query_data.get("filter"):
                st.json(query_data["filter"])
            else:
                st.info("No filters extracted")
            
            # Show elastic queries
            st.subheader("üîß Elasticsearch Queries")
            if query_data.get("elastic_query"):
                for i, eq in enumerate(query_data["elastic_query"]):
                    st.markdown(f"**Query {i + 1}:**")
                    st.json(eq)
            else:
                st.info("No Elasticsearch queries generated")
                
        else:
            # Show error
            st.error(f"Error: {query_data.get('error', 'Missing filter or elastic_query data')}")


def DisplayLiveQueryResult(query_data: dict):
    """Display a live query result with better formatting."""
    status = query_data.get("status", "error")
    status_icon = "‚úÖ" if status == "success" else "‚ùå"
    status_color = "green" if status == "success" else "red"
    
    st.markdown(f"### {status_icon} Query Result")
    st.markdown(f"**Status:** :{status_color}[{status.upper()}]")
    
    if status == "success":
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üîç Extracted Filters")
            if query_data.get("filter"):
                st.json(query_data["filter"])
            else:
                st.info("No filters extracted")
        
        with col2:
            st.subheader("üîß Elasticsearch Queries")
            if query_data.get("elastic_query"):
                for i, eq in enumerate(query_data["elastic_query"]):
                    st.markdown(f"**Query {i + 1}:**")
                    st.json(eq)
            else:
                st.info("No Elasticsearch queries generated")
    else:
        st.error(f"Error: {query_data.get('error', 'Unknown error')}")


def FilterData(data: list, status_filter: str, search_term: str) -> list:
    """Filter data based on status and search term."""
    filtered = data
    
    # Filter by status
    if status_filter != "All":
        filtered = [
            item for item in filtered 
            if (lambda item: "success" if (item.get("filter") is not None and item.get("elastic_query") is not None) else "error")(item) == status_filter.lower()
        ]
    
    # Filter by search term
    if search_term:
        filtered = [
            item for item in filtered 
            if search_term.lower() in item.get("input", "").lower()
        ]
    
    return filtered


def RunStreamlitViewer():
    """Main Streamlit interface for viewing query results."""
    st.set_page_config(
        page_title="Elasticsearch Query Viewer",
        page_icon="üìä",
        layout="wide"
    )
    
    st.title("üìä Elasticsearch Query Results Viewer")
    st.markdown("View and analyze results from processed natural language queries")
    
    # Create tabs for different sections
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["üîç Live Query", "üìã Saved Queries", "üìã Model Info", "üìö Documentation", "üß∞ ES Query Runner"])
    
    with tab1:
        st.header("üîç Live Query Processing")
        st.markdown("Enter a natural language query to see how it's processed in real-time")
        
        # Query input
        query_input = st.text_area(
            "Enter your query:",
            placeholder="e.g., 'Show me all transactions from last month' or 'How much did I spend on food?'",
            height=100
        )
        
        col1, col2, col3 = st.columns([1, 1, 4])
        
        with col1:
            process_button = st.button("üöÄ Process Query", type="primary")
        
        with col2:
            save_format = st.selectbox("Save as:", ["JSON", "Excel"], key="save_format")
            if st.button("üíæ Save to File"):
                if query_input.strip():
                    if 'live_result' in st.session_state:
                        # Determine filename based on format
                        if save_format == "JSON":
                            filename = "example_queries.json"
                        else:
                            filename = "example_queries.xlsx"
                        
                        # Load existing data
                        existing_data = LoadData(filename)
                        
                        # Add timestamp to the result
                        result_to_save = st.session_state.live_result.copy()
                        result_to_save["timestamp"] = datetime.now().isoformat()
                        
                        existing_data.append(result_to_save)
                        
                        # Save data
                        if SaveData(existing_data, filename):
                            st.success(f"Query saved to {filename}!")
                        else:
                            st.error(f"Failed to save to {filename}")
                    else:
                        st.warning("Please process a query first before saving")
                else:
                    st.warning("Please enter a query first")
        
        # Process the query
        if process_button and query_input.strip():
            with st.spinner("Processing query..."):
                result = ProcessLiveQuery(query_input.strip())
                st.session_state.live_result = result
        
        # Display result if available
        if 'live_result' in st.session_state:
            st.divider()
            DisplayLiveQueryResult(st.session_state.live_result)
        
        # Example queries
        st.divider()
        st.subheader("üí° Example Queries")
        example_queries = [
            "Show me all transactions from last month",
            "How much did I spend on food?",
            "What are my recent deposits?",
            "Transactions over $100 in December",
            "Compare hotel spending with restaurant spending"
        ]
        
        cols = st.columns(len(example_queries))
        for i, example in enumerate(example_queries):
            with cols[i]:
                if st.button(f"Try: {example[:20]}...", key=f"example_{i}"):
                    st.session_state.example_query = example
                    st.rerun()
        
        # Auto-fill from example if selected
        if 'example_query' in st.session_state:
            st.text_area(
                "Selected example query:",
                value=st.session_state.example_query,
                height=60,
                key="example_display"
            )
            if st.button("üöÄ Process Example", type="primary"):
                with st.spinner("Processing example query..."):
                    result = ProcessLiveQuery(st.session_state.example_query)
                    st.session_state.live_result = result
                    st.rerun()
    
    with tab2:
        st.header("üìã Saved Query Results")
        
        # Sidebar controls
        with st.sidebar:
            st.header("Controls")
            
            # File selection
            st.subheader("üìÇ Data Source")
            source_type = st.radio("Data Source:", ["Local File", "Upload File"], horizontal=True)
            
            if source_type == "Local File":
                file_type = st.radio("File Type:", ["JSON", "Excel"], horizontal=True)
                
                if file_type == "JSON":
                    data_file = st.text_input("JSON File:", value="example_queries.json")
                else:
                    data_file = st.text_input("Excel File:", value="example_queries.xlsx", help="Supports .xlsx and .xls files")
            else:
                uploaded_file = st.file_uploader(
                    "Upload your data file:",
                    type=['json', 'xlsx', 'xls'],
                    help="Upload a JSON or Excel file containing query data"
                )
                
                if uploaded_file is not None:
                    # Save uploaded file temporarily
                    temp_path = Path(f"temp_{uploaded_file.name}")
                    temp_path.write_bytes(uploaded_file.getvalue())
                    data_file = str(temp_path)
                else:
                    data_file = None
            
            # Refresh button
            if st.button("üîÑ Refresh Data"):
                st.rerun()
            
            # Load data
            if data_file is None:
                st.info("Please select or upload a data file")
                return
                
            data = LoadData(data_file)
            
            if not data:
                st.warning(f"No data found in {data_file}")
                st.info("Run elasticsearch_model_generator.py to generate data or check your file format")
                return
            
            st.success(f"Loaded {len(data)} queries")
            
            # Debug information
            if st.checkbox("Show Debug Info"):
                st.subheader("üîç Debug Information")
                if data:
                    # Validate data structure
                    validation = ValidateDataStructure(data)
                    
                    if validation["valid"]:
                        st.success("‚úÖ Data structure is valid")
                    else:
                        st.warning("‚ö†Ô∏è Data structure issues detected")
                        if validation.get("issues"):
                            for issue in validation["issues"]:
                                st.error(f"‚Ä¢ {issue}")
                    
                    if validation.get("fixed_items", 0) > 0:
                        st.info(f"üîß Automatically fixed {validation['fixed_items']} items (mapped 'query' to 'input')")
                    
                    # Show sample data structure
                    sample_item = data[0]
                    st.markdown("**Sample data structure:**")
                    st.json(sample_item)
                    st.markdown("**Available keys:**")
                    st.write(list(sample_item.keys()))
                    
                    # Show data statistics
                    st.markdown("**Data Statistics:**")
                    st.write(f"Total items: {validation['total_items']}")
                    st.write(f"Sample keys: {validation['sample_keys']}")
                else:
                    st.info("No data to debug")
            
            # Filters
            st.subheader("Filters")
            
            # Status filter
            status_options = ["All", "success", "error"]
            status_filter = st.selectbox("Status:", status_options)
            
            # Search filter
            search_term = st.text_input("Search in queries:")
            
            # Apply filters
            filtered_data = FilterData(data, status_filter, search_term)
            
            st.info(f"Showing {len(filtered_data)} of {len(data)} queries")
        
        # Main content
        if not data:
            st.info("No data to display. Run the elasticsearch_model_generator.py script to generate query data.")
            
            # Show expected file format
            st.subheader("üìù Expected File Format")
            
            if source_type == "Local File" and file_type == "Excel":
                st.markdown("**Excel files should contain columns (flexible naming):**")
                st.markdown("- `input` / `Query` / `Natural_Language_Query`: The natural language query")
                st.markdown("- `filter` / `Extracted_Filters`: JSON string of extracted filters")
                st.markdown("- `elastic_query` / `Elasticsearch_Queries`: JSON string of Elasticsearch queries")
                st.markdown("- `status` / `API_Status`: Query processing status")
                st.markdown("- `timestamp` / `Processing_Time`: When the query was processed")
                st.markdown("- `error` / `Error_Message`: Error message (if any)")
            else:
                st.markdown("**JSON files should contain an array of objects with:**")
                st.code('''[
  {
    "input": "Show me transactions over $100",
    "filter": {...},
    "elastic_query": [...],
    "status": "success",
    "timestamp": "2024-01-01T00:00:00",
    "error": null
  }
]''', language="json")
            
            return
        
        # Query results
        if not filtered_data:
            st.info("No queries match the current filters.")
            return
        
        # Display queries
        for i, query_data in enumerate(filtered_data):
            DisplayQueryCard(query_data, i)
    
    with tab3:
        st.header("üìã Model Information")
        st.markdown("Understanding the data schema and available fields for querying")
        
        # Load model info
        try:
            from elasticsearch_model_generator import ElasticsearchModelGenerator
            
            client = ElasticsearchModelGenerator(
                index_name="user_transactions",
                category_fields=[
                    "card_kind",
                    "card_type", 
                    "transaction.receiver.category_type",
                    "transaction.receiver.location",
                    "transaction.type",
                    "transaction.currency"
                ],
                fields_to_ignore=["user_id", "card_number"],
            )
            
            # Add debug section
            with st.expander("üîß Debug Information", expanded=False):
                st.markdown("**Debug category field processing**")
                
                if st.button("Run Debug Check"):
                    with st.spinner("Running debug check..."):
                        debug_info = client.debug_category_fields()
                        
                        st.subheader("Configured Category Fields")
                        st.json(debug_info["configured_category_fields"])
                        
                        st.subheader("Processing Results")
                        for field, info in debug_info["processed_fields"].items():
                            col1, col2 = st.columns([1, 2])
                            with col1:
                                st.markdown(f"**{field}**")
                                st.markdown(f"Values found: {info['distinct_values_found']}")
                            with col2:
                                if info['distinct_values_found'] > 0:
                                    st.markdown(f"Field path: `{info['field_path_used']}`")
                                    st.markdown(f"Sample values: {info['sample_values']}")
                                else:
                                    st.error("No values found - field might not exist or have no data")
                        
                        if debug_info["errors"]:
                            st.subheader("‚ùå Errors")
                            for error in debug_info["errors"]:
                                st.error(error)
                        
                        st.subheader("Available Fields in Index")
                        available_fields = debug_info.get("available_fields", [])
                        if available_fields:
                            # Show fields that might be category fields
                            potential_category_fields = [f for f in available_fields if any(cat in f for cat in ["type", "category", "currency", "location", "kind"])]
                            if potential_category_fields:
                                st.markdown("**Potential category fields:**")
                                for field in potential_category_fields:
                                    st.markdown(f"‚Ä¢ `{field}`")
                            
                            # Show all fields in a searchable format
                            search_available = st.text_input("Search available fields:", key="search_available")
                            filtered_available = [f for f in available_fields if not search_available or search_available.lower() in f.lower()]
                            st.markdown(f"**All available fields ({len(filtered_available)}/{len(available_fields)}):**")
                            for field in filtered_available[:20]:  # Show first 20
                                st.markdown(f"‚Ä¢ `{field}`")
                            if len(filtered_available) > 20:
                                st.markdown(f"*... and {len(filtered_available) - 20} more*")
            
            with st.spinner("Loading model information..."):
                model_info = client.get_model_info()
                
            # Display model summary
            st.subheader("üìä Schema Overview")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total Fields", len(model_info))
            
            with col2:
                enum_fields = sum(1 for field in model_info.values() if field.get("type") == "enum")
                st.metric("Enum Fields", enum_fields)
            
            with col3:
                array_fields = sum(1 for field in model_info.values() if field.get("type") == "array")
                st.metric("Array Fields", array_fields)
            
            # Field type distribution
            st.subheader("üìà Field Type Distribution")
            type_counts = {}
            for field_info in model_info.values():
                field_type = field_info.get("type", "unknown")
                type_counts[field_type] = type_counts.get(field_type, 0) + 1
            
            # Display as columns
            type_cols = st.columns(len(type_counts))
            for i, (field_type, count) in enumerate(type_counts.items()):
                with type_cols[i]:
                    st.metric(field_type.title(), count)
            
            # Searchable field list
            st.subheader("üîç Field Explorer")
            
            # Search functionality
            search_field = st.text_input("Search fields:", placeholder="e.g., 'transaction', 'amount', 'category'")
            
            # Filter fields based on search
            filtered_fields = {}
            for field_name, field_info in model_info.items():
                if not search_field or search_field.lower() in field_name.lower():
                    filtered_fields[field_name] = field_info
            
            if search_field and not filtered_fields:
                st.info(f"No fields found matching '{search_field}'")
            
            # Display fields in expandable sections
            st.markdown(f"**Showing {len(filtered_fields)} of {len(model_info)} fields**")
            
            # Group fields by type for better organization
            field_groups = {}
            for field_name, field_info in filtered_fields.items():
                field_type = field_info.get("type", "unknown")
                if field_type not in field_groups:
                    field_groups[field_type] = []
                field_groups[field_type].append((field_name, field_info))
            
            # Display each group
            for field_type, fields in field_groups.items():
                with st.expander(f"{field_type.title()} Fields ({len(fields)})", expanded=field_type == "enum"):
                    for field_name, field_info in sorted(fields):
                        col1, col2 = st.columns([2, 3])
                        
                        with col1:
                            st.markdown(f"**`{field_name}`**")
                            st.markdown(f"*Type: {field_info.get('type', 'unknown')}*")
                            
                            if field_info.get("is_array_item"):
                                st.markdown("*Part of array structure*")
                        
                        with col2:
                            if field_info.get("type") == "enum":
                                values = field_info.get("values", [])
                                if values:
                                    st.markdown("**Available values:**")
                                    # Display values in a more compact format
                                    if len(values) <= 10:
                                        for value in values:
                                            st.markdown(f"‚Ä¢ `{value}`")
                                    else:
                                        # Show first 8 values and indicate more
                                        for value in values[:8]:
                                            st.markdown(f"‚Ä¢ `{value}`")
                                        st.markdown(f"*... and {len(values) - 8} more values*")
                                else:
                                    st.markdown("*No enum values available*")
                            
                            elif field_info.get("type") == "array":
                                item_type = field_info.get("item_type", "unknown")
                                st.markdown(f"**Array of:** {item_type}")
                                
                                if field_info.get("values"):
                                    st.markdown("**Possible values:**")
                                    values = field_info.get("values", [])
                                    if len(values) <= 5:
                                        for value in values:
                                            st.markdown(f"‚Ä¢ `{value}`")
                                    else:
                                        for value in values[:5]:
                                            st.markdown(f"‚Ä¢ `{value}`")
                                        st.markdown(f"*... and {len(values) - 5} more*")
                            
                            else:
                                # For basic types, show example usage
                                examples = {
                                    "string": "e.g., 'restaurant', 'online'",
                                    "number": "e.g., 100, 250.50",
                                    "boolean": "e.g., true, false",
                                    "date": "e.g., '2024-01-01'"
                                }
                                if field_info.get("type") in examples:
                                    st.markdown(f"**Example:** {examples[field_info.get('type')]}")
                        
                        st.divider()
            
            # Query examples section
            st.subheader("üí° Query Examples by Field Type")
            
            example_queries = {
                "Enum Fields": [
                    "Show me all GOLD card transactions",
                    "What purchases did I make at restaurants?",
                    "Transactions in New York"
                ],
                "Number Fields": [
                    "Transactions over $100",
                    "Spending less than $50",
                    "Amount between $20 and $200"
                ],
                "Date Fields": [
                    "Transactions from last month",
                    "Spending in January 2024",
                    "Recent deposits"
                ],
                "String Fields": [
                    "Transactions at Starbucks",
                    "Purchases containing 'coffee'",
                    "Online transactions"
                ]
            }
            
            for category, queries in example_queries.items():
                with st.expander(f"{category} Examples"):
                    for query in queries:
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.markdown(f"‚Ä¢ {query}")
                        with col2:
                            if st.button("Try", key=f"try_{query}"):
                                st.session_state.example_query = query
                                st.switch_page("üîç Live Query")
            
        except Exception as e:
            st.error(f"Error loading model information: {str(e)}")
            st.info("Make sure the elasticsearch_model_generator.py file is accessible and the Elasticsearch connection is working.")
    
    with tab4:
        st.header("How to Build Your Queries")
        st.markdown(
            "This guide explains how you can formulate questions to get the data you need. "
            "Your questions are built from three main components: **Fields**, **Operators**, and **Values**."
        )
        
        st.divider()

        st.subheader("1. Fields: Your Searchable Data")
        st.markdown(
            "Fields are the different data points you can search on. For example, `amount`, `transaction_date`, or `transaction.receiver.category_type`."
        )
        st.info(
            "**To see a complete list of all available fields, their types, and example values, please visit the 'Model Info' tab.**"
        )
        
        st.divider()

        st.subheader("2. Operators: How You Filter the Data")
        st.markdown("Operators are the actions you use to filter your data. Here are the ones you can use:")
        
        operator_data = {
            "Operator": ["is", "is not", "is in", "is not in", "> (greater than)", "< (less than)", "between"],
            "Example Usage": [
                "`category is 'food'`",
                "`status is not 'pending'`", 
                "`category is in ['food', 'travel']`",
                "`location is not in ['online', 'web']`",
                "`amount > 100`",
                "`amount < 50`",
                "`date between '2024-01-01' and '2024-06-01'`"
            ]
        }
        import pandas as pd
        st.dataframe(pd.DataFrame(operator_data), use_container_width=True, hide_index=True)
        
        st.divider()

        st.subheader("3. Values: The Specifics of Your Query")
        st.markdown("Values are the specific pieces of information you're looking for.")
        st.markdown(
            """
            - **For Text fields**: Use single quotes, like `'food'` or `'GOLD'`.
            - **For Number fields**: Use numbers, like `100` or `50.25`.
            - **For Date fields**: Use the `YYYY-MM-DD` format, like `'2024-01-15'`.
            """
        )

        st.divider()

        st.header("Examples: Putting It All Together")
        st.markdown("Here‚Äôs how these building blocks combine to answer your questions.")

        st.markdown("##### To find specific transactions (Single Filter):")
        st.code("Show me transactions over $100 at restaurants.", language="text")
        st.markdown("**How it's understood:**")
        st.json({
            "filters": [[
                {"field": "amount", "operator": ">", "value": 100},
                {"field": "transaction.receiver.category_type", "operator": "is", "value": "restaurant"}
            ]]
        })

        st.markdown("##### To compare two sets of data (Comparison):")
        st.code("Compare food spending vs travel spending.", language="text")
        st.markdown("**How it's understood:**")
        st.json({
            "filters": [
                [{"field": "transaction.receiver.category_type", "operator": "is", "value": "food"}],
                [{"field": "transaction.receiver.category_type", "operator": "is", "value": "travel"}]
            ]
        })

    with tab5:
        st.header("üß∞ Elasticsearch Raw Query Runner")
        st.markdown("Directly execute any valid Elasticsearch query against the `user_transactions` index.")

        default_query = {
            "query": {
                "match_all": {}
            },
            "size": 10
        }
        
        query_text = st.text_area(
            "Enter your Elasticsearch query (JSON format):",
            value=json.dumps(default_query, indent=2),
            height=300,
            key="raw_es_query"
        )

        if st.button("‚ö° Execute Raw Query", type="primary"):
            if query_text.strip():
                try:
                    query_json = json.loads(query_text)
                    
                    with st.spinner("Executing raw query..."):
                        result = ProcessRawESQuery(query_json)
                        st.session_state.raw_es_result = result

                except json.JSONDecodeError:
                    st.error("Invalid JSON. Please check your query format.")
                except Exception as e:
                    st.error(f"An error occurred: {e}")
            else:
                st.warning("Please enter a query.")

        if 'raw_es_result' in st.session_state:
            st.divider()
            st.subheader("Query Results")
            result = st.session_state.raw_es_result
            
            if "error" in result:
                st.error(f"Execution Error: {result['error']}")
                st.json(result.get('query'))
            else:
                st.success(f"Query executed successfully. Total hits: {result.get('total_hits', 0)}")
                
                st.markdown("#### Documents")
                if result.get("documents"):
                    st.json(result.get("documents", []))
                else:
                    st.info("No documents returned.")
                
                # Show aggregations if they exist in the raw response
                if result.get("aggregations"):
                    st.markdown("#### Aggregations")
                    st.json(result.get("aggregations", {}))
                
                with st.expander("Show Executed Query"):
                    st.json(result.get('query'))


if __name__ == "__main__":
    RunStreamlitViewer() 
    

